{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 08:48:49,444 - INFO - Starting scrape for https://www.ireland.ie/en/spain/madrid/news-and-events/news-archive/visa-faqs/\n",
      "2025-03-10 08:48:50,260 - INFO - Saved 20 FAQs to 'spain_visa_faqs.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"scrape_spain_visa_log.log\", encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def scrape_spain_visa_faqs(url, output_file=\"spain_visa_faqs.csv\"):\n",
    "    \"\"\"Scrape FAQs from the specified Ireland.ie Spain visa FAQ page.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Starting scrape for {url}\")\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            logger.error(f\"Failed to retrieve {url}. Status code: {response.status_code}\")\n",
    "            return\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        main_content = soup.find(id=\"main-content\")\n",
    "        \n",
    "        if not main_content:\n",
    "            logger.error(\"Main content with ID 'main-content' not found.\")\n",
    "            return\n",
    "        \n",
    "        # Target the specific div structure: //*[@id=\"main-content\"]/div[1]/div[4] to div[23]\n",
    "        faq_container = main_content.find('div')\n",
    "        if not faq_container:\n",
    "            logger.error(\"First div inside 'main-content' not found.\")\n",
    "            return\n",
    "        \n",
    "        faq_data = []\n",
    "        for i in range(4, 24):  # div[4] to div[23] inclusive\n",
    "            faq_div = faq_container.select_one(f'div:nth-of-type({i})')\n",
    "            if not faq_div:\n",
    "                logger.warning(f\"Div[{i}] not found in main-content.\")\n",
    "                continue\n",
    "            \n",
    "            # Find question (class: story__heading heading--2)\n",
    "            question_elem = faq_div.find(class_=[\"story__heading\", \"heading--2\"])\n",
    "            question = question_elem.get_text(strip=True) if question_elem else \"Question not found\"\n",
    "            \n",
    "            # Find answer (class: rich_text__summary)\n",
    "            answer_elem = faq_div.find(class_=\"rich_text__summary\")\n",
    "            answer_text = \"\"\n",
    "            \n",
    "            if answer_elem:\n",
    "                # Extract nested content (paragraphs, lists, etc.)\n",
    "                for elem in answer_elem.children:\n",
    "                    if elem.name == 'p':\n",
    "                        answer_text += elem.get_text(strip=True) + \"\\n\"\n",
    "                    elif elem.name == 'ul':\n",
    "                        for li in elem.find_all('li'):\n",
    "                            answer_text += f\"- {li.get_text(strip=True)}\\n\"\n",
    "                    elif elem.name == 'ol':\n",
    "                        for li in elem.find_all('li'):\n",
    "                            answer_text += f\"{li.get_text(strip=True)}\\n\"\n",
    "                    elif elem.name == 'div':\n",
    "                        answer_text += elem.get_text(strip=True) + \"\\n\"\n",
    "                answer_text = answer_text.strip()\n",
    "            else:\n",
    "                answer_text = \"Answer not found\"\n",
    "                logger.debug(f\"No answer found for div[{i}]\")\n",
    "            \n",
    "            if question != \"Question not found\" or answer_text != \"Answer not found\":\n",
    "                faq_data.append({\n",
    "                    \"Website\": url,\n",
    "                    \"Question\": question,\n",
    "                    \"Answer\": answer_text\n",
    "                })\n",
    "        \n",
    "        # Save to CSV\n",
    "        if faq_data:\n",
    "            with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                fieldnames = [\"Website\", \"Question\", \"Answer\"]\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(faq_data)\n",
    "            logger.info(f\"Saved {len(faq_data)} FAQs to '{output_file}'\")\n",
    "        else:\n",
    "            logger.warning(\"No FAQs found to save.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during scrape: {str(e)}\")\n",
    "\n",
    "# URL to scrape\n",
    "url = \"https://www.ireland.ie/en/spain/madrid/news-and-events/news-archive/visa-faqs/\"\n",
    "\n",
    "# Run the scraper\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_spain_visa_faqs(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
